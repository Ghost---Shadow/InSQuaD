wandb:
  project: "quaild"
  name: "gc_test_experiment"
  # entity: "carml"

architecture:
  generative_model:
    type: 'noop'
    checkpoint: 'none'
    device: 'none'
  
  semantic_search_model:
    type: 'mpnet'
    checkpoint: 'sentence-transformers/all-mpnet-base-v2'
    device: "cuda:0"

  subset_selection_strategy:
    type: 'graph_cut'
    k: 20 # Annotation budget

  dense_index:
    type: 'faiss'
    index_class: 'IndexFlatL2'
    repopulate_every: 'epoch'
    k_for_rerank: 10

  prompt_formatting_strategy:
    type: 'q_a_with_new_line'

# https://arxiv.org/pdf/2004.09297.pdf - Page 12
training:
  type: 'noop'
  dataset: 'dummy_hotpot_qa_with_q'
  q_d_tradeoff_lambda: 0.5
  extra_metrics: ['hotpot_qa_with_q_f1']
  epochs: 7
  batch_size: 32
  learning_rate: 3e-5
  weight_decay: 0.01
  learning_rate_decay_strategy: 'linear'
  warmup_ratio: 0.06
  seeds: [42]
  loss:
    type: 'graph_cut'
    lambd: 0.5

offline_validation:
  type: shortlist_then_top_k
  generative_model:
    type: 'automodel'
    checkpoint: 'EleutherAI/gpt-neo-125m'
    device: "cuda:0"
  datasets: ['mrpc']
  seeds: [42]
  num_shots: 5
  annotation_budget: 20
  subsample_for_train_size: 300
  subsample_for_eval_size: 256
